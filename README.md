# Разработка юридического ассистента на основе LLM

## Постановка задачи

Разработка модуля интеллектуального поиска документов в базе данных (retriever)
для юридического ассистента, основанного на больших языковых моделях (LLM).

На текущий момент без помощи юриста сложно быстро находить нужные статьи и
законы в больших объёмах правовых документов. Разрабатываемый модуль retrieval
будет помогать в этом: он сможет по конкретному запросу пользователя находить
релевантные фрагменты законов и нормативных актов, подготавливая контекст для
последующей обработки ассистентом.

Для обеспечения корректного и точного поиска требуется обученная векторная
модель, способная:

- понимать контекст нормативно-правовых актов,
- находить семантически близкие фрагменты,
- корректно ранжировать результаты,
- готовить контекст для последующей генерации ответа LLM.

В рамках проекта разрабатывается retrieval-модель, а также создаётся векторная
база данных, на которой будет основана работа юридического ассистента.

## Формат входных и выходных данных

### Входные данные

**Пользовательский запрос:**

- строка (str, 5–200 символов), например:
  ```
  "Какие штрафы предусмотрены за нарушение условий договора с поставщиком?"
  ```

## Метрики

Для задачи retrieval-поиска ключевые метрики:

### 1. Recall@k

Показывает, найден ли правильный фрагмент среди первых k результатов.

Высокий recall важнее precision, т.к. retrieved документы затем проходят
reranking/LLM-обработку.

### 2. MRR (Mean Reciprocal Rank)

Отражает позицию первого релевантного ответа.

### 3. nDCG@k (Normalized Discounted Cumulative Gain)

Оценивает качество ранжирования с учетом позиции релевантных результатов.

## Валидация и тест

Для оценки качества используется схема:

- **Train** — 70% документов
- **Test** — 15% документов

Разделение выполняется по документам, а не по чанкам, чтобы избежать утечки
информации: чанки одного и того же закона не должны попасть в train и test
одновременно.

Детерминированность и воспроизводимость достигается фиксированием random seed.

## Датасеты

Используемые источники юридических данных:

### 1. [Russian Legal Documents](https://www.kaggle.com/datasets/nzibben/20-russian-legal-documents)

Около 2000 страниц российских юридических документов. На русском языке. В
сборнике датасетов есть файлы docx, rtf форматов (в них около 800 000 слов),
файлы pdf формата (в них около 1 500 000 слов). Общий вес документов 118.03 Мб.

### 2. [Rossiyskaya Gazeta Papers (Russian legal texts)](https://www.kaggle.com/datasets/athugodage/russian-legal-text-parallel-corpus)

Данные с веб-сайта "Российской газеты", издаваемой правительством России уже в
формате csv. Набор данных содержит законодательные документы с 31 декабря 2008
года по 28 ноября 2022 года. Всего в датасете 2963 семпла (154.81 Мб). Датасет
содержит 5 колонок:

- Название документа (Document Title)
- Ссылка (Link to the original document)
- Текст (Original document text)
- Комментарий РГ (Rossiyskaya Gazeta comment)
- Дата (Publication date)

## Моделирование

### Бейзлайн

Базовое решение: использование предобученной модели эмбеддингов без дообучения,
например:

- **DeepPavlov/rubert-base-cased-sentence** (простая небольшая модель)

**Приблизительный план работы:**

1. чанкование документов
2. создание эмбеддингов
3. поиск ближайших векторов по cosine similarity

Качество модели рассчитается на описанных выше метриках. На их основе будет
сравниваться основные модели.

### Основная модель

Планируется использование более тяжелых моделей по сравнению с бейзлайном.
Возможные варианты:

- **Multilingual E5** (Мультиязычная модель с поддержкой русского языка. Размер
  модели – 600М параметров)
- **ru-en-RoSBERTa** (Модель bert с поддержкой русского языка. Размер – 400М
  параметров)
- **xlm-roberta-large** (Мультиязычная модель с поддержкой русского языка.
  Размер модели – 600М параметров)

**Способ обучения:**

1. чанкование документов;
2. составление позитивных/негативных пар:
   - позитив: соседние чанки одной статьи;
   - негатив: чанки разных законов;
3. обучение модели: Обучение модели проходит с использованием контрастивного
   обучения (InfoNCE Loss) и косинусного сходства между парами текстов.

## Внедрение

Модель будет использоваться как компонент юридического ассистента (именно ее
retrieval часть).

**Архитектура:**

- **Векторная база данных:** Qdrant
- **API-сервис на FastAPI:**
  - `/embed` — генерация эмбеддингов
  - `/search` — поиск релевантных фрагментов
  - `/answer` — подготовка контекста для LLM

**Пайплайн будет включать:**

1. предобработку текстов законов;
2. чанкирование;
3. создание эмбеддингов;
4. индексирование в векторную БД;
5. пул запросов от пользователя.

---

## Технические детали

### Setup

#### Требования

- Python 3.12+
- [uv](https://github.com/astral-sh/uv) — менеджер пакетов и окружений
- Qdrant — векторная база данных (локально или облачная)
- CUDA (опционально, для GPU-ускорения)

#### Установка зависимостей

Склонировать репозиторий и перейти в директорию проекта:

```bash
cd russian_laws
```

Установить зависимости проекта:

```bash
uv sync
```

Настроить переменные окружения:

Создать файл `.env` в корне проекта (или экспортировать переменные):

```bash
export QDRANT_URL="your_host"
export QDRANT_API_KEY="your_api_key"

export AWS_ACCESS_KEY_ID="your_access_key"
export AWS_SECRET_ACCESS_KEY="your_secret_key"
```

#### Установка dev-зависимостей (опционально)

Для разработки и работы с данными:

```bash
uv sync --group dev
```

#### Настройка pre-commit

Для автоматической проверки кода:

```bash
uv run pre-commit install
```

### Train

#### Обучение моделей

Запуск обучения всех моделей, указанных в конфигурации:

```bash
uv run python russian_laws/train.py run_training
```

#### Просмотр метрик в MLflow

Запустите MLflow UI:

```bash
uv run mlflow ui
```

### Test

#### Запуск тестирования

Тестирование модели на тестовом датасете:

```bash
uv run python russian_laws/test.py run_test
```

**Результаты:**

- Метрики (Recall@k, nDCG@k, MRR) логируются в MLflow
- Результаты выводятся в консоль

### API

#### Запуск FastAPI сервиса

Запуск API сервиса с обученной моделью:

```bash
uv run python russian_laws/api.py
```

**Важно:** Убедитесь, что:

1. Модель обучена и находится в `data/models/rubert_base/last.ckpt`
2. Статьи проиндексированы в Qdrant

#### Эндпоинты API

После запуска сервиса доступны следующие эндпоинты:

- **`GET /`** — информация о сервисе
- **`GET /health`** — проверка здоровья сервиса
- **`POST /embed`** — генерация эмбеддинга для текста
  ```json
  {
    "text": "Ваш текст для эмбеддинга"
  }
  ```
- **`POST /search`** — поиск релевантных статей
  ```json
  {
    "query": "Ваш запрос",
    "limit": 10,
    "score_threshold": 0.5
  }
  ```
- **`POST /answer`** — подготовка контекста для LLM
  ```json
  {
    "query": "Ваш вопрос",
    "limit": 5
  }
  ```

### Структура проекта

```
russian_laws/
├── conf/                    # Конфигурации Hydra
│   ├── config.yaml          # Основной конфиг
│   ├── embedding/           # Конфигурация модели эмбеддингов
│   ├── qdrant/              # Конфигурация Qdrant
│   └── train/               # Конфигурация обучения
├── data/
│   ├── models/              # Обученные модели
│   ├── processed/           # Обработанные данные
│   └── raw/                 # Исходные данные
├── russian_laws/            # Основной пакет
│   ├── api.py               # FastAPI сервис
│   ├── embeddings.py        # Модель эмбеддингов
│   ├── metrics.py           # Метрики retrieval
│   ├── qdrant_manager.py    # Менеджер Qdrant
│   ├── test.py              # Тестирование моделей
│   └── train.py             # Обучение моделей
├── scripts/                 # Вспомогательные скрипты
│   └── download_files.sh    # Загрузка данных из DVC
└── pyproject.toml           # Зависимости проекта
```
